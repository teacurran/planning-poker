# ==========================================
# Application Configuration
# ==========================================
quarkus.application.name=scrum-poker-backend

# ==========================================
# Database Configuration (PostgreSQL)
# ==========================================
# Database kind (applies to all profiles)
quarkus.datasource.db-kind=postgresql

# Connection pool settings (applies to all profiles)
# PRODUCTION NOTE: For high load (5,000 concurrent WebSocket connections), increase pool size
# Recommended: 50-100 connections for sustained load with burst traffic
# Formula: Consider average query time × concurrent queries
# WARNING: Ensure PostgreSQL max_connections is sufficiently high (recommended: 300+)
quarkus.datasource.reactive.max-size=${DB_POOL_MAX_SIZE:20}
quarkus.datasource.reactive.idle-timeout=${DB_POOL_IDLE_TIMEOUT:PT10M}
quarkus.datasource.reactive.max-lifetime=${DB_POOL_MAX_LIFETIME:PT30M}
quarkus.datasource.reactive.acquisition-timeout=${DB_POOL_ACQUISITION_TIMEOUT:10}

# Production datasource configuration (will be overridden by environment variables in production)
%prod.quarkus.datasource.username=${DB_USERNAME:postgres}
%prod.quarkus.datasource.password=${DB_PASSWORD:postgres}
%prod.quarkus.datasource.jdbc.url=${DB_JDBC_URL:jdbc:postgresql://localhost:5432/scrumpoker}
%prod.quarkus.datasource.reactive.url=${DB_REACTIVE_URL:postgresql://localhost:5432/scrumpoker}

# Hibernate Reactive configuration
quarkus.hibernate-orm.database.generation=validate
quarkus.hibernate-orm.log.sql=${DB_LOG_SQL:false}
quarkus.hibernate-orm.log.bind-parameters=false

# ==========================================
# Database Migrations (Flyway)
# ==========================================
# Enabled after I1.T3 database migration scripts completion
# Set FLYWAY_MIGRATE=false environment variable to disable if needed
quarkus.flyway.migrate-at-start=${FLYWAY_MIGRATE:true}
quarkus.flyway.locations=classpath:db/migration
quarkus.flyway.baseline-on-migrate=true
quarkus.flyway.baseline-version=0

# ==========================================
# Redis Configuration
# ==========================================
# Redis connection (for prod and dev profiles - tests use Dev Services/Testcontainers)
%prod.quarkus.redis.hosts=${REDIS_URL:redis://localhost:6379}
%dev.quarkus.redis.hosts=${REDIS_URL:redis://localhost:6379}
quarkus.redis.client-type=standalone

# Redis connection pool settings
# PRODUCTION NOTE: For high load with 5,000 WebSocket connections and Pub/Sub broadcasting
# Recommended: 50-100 connections for concurrent session caching and message broadcasting
# Monitor Redis INFO clients during load testing to verify pool sizing
quarkus.redis.max-pool-size=${REDIS_POOL_MAX_SIZE:20}
quarkus.redis.max-pool-waiting=${REDIS_POOL_MAX_WAITING:50}

# Redis timeout configuration
quarkus.redis.timeout=${REDIS_TIMEOUT:10s}

# Redis reconnection attempts
quarkus.redis.max-reconnect-attempts=${REDIS_MAX_RECONNECT_ATTEMPTS:10}
quarkus.redis.reconnect-interval=${REDIS_RECONNECT_INTERVAL:1s}

# Redis health check
quarkus.redis.health.enabled=true

# ==========================================
# JWT Configuration
# ==========================================
# JWT token issuer (must match issuer claim in generated tokens)
mp.jwt.verify.issuer=${JWT_ISSUER:https://scrumpoker.com}

# JWT token public key location (for signature verification)
# PRODUCTION NOTE: In production, set JWT_PUBLIC_KEY environment variable with actual key content
# instead of using file location. For development, the file location is used.
mp.jwt.verify.publickey.location=${JWT_PUBLIC_KEY_LOCATION:/publicKey.pem}

# JWT signing key location (for token generation - PRIVATE KEY)
# PRODUCTION NOTE: In production, this MUST be loaded from Kubernetes Secrets or secure vault
# via the JWT_PRIVATE_KEY environment variable containing the actual key content.
# NEVER commit privateKey.pem to version control (already in .gitignore).
smallrye.jwt.sign.key.location=${JWT_PRIVATE_KEY_LOCATION:/privateKey.pem}

# JWT access token expiration time in seconds (1 hour = 3600 seconds)
mp.jwt.token.expiration=${JWT_TOKEN_EXPIRATION:3600}

# Refresh token expiration in seconds (30 days = 2592000 seconds)
# Note: Refresh tokens are stored in Redis with this TTL, not in JWT itself
mp.jwt.refresh.token.expiration=${JWT_REFRESH_TOKEN_EXPIRATION:2592000}

# ==========================================
# OIDC Configuration (OAuth2/SSO)
# ==========================================
# Multi-tenant OIDC configuration for Google and Microsoft OAuth2 providers
# Uses environment variables for production credentials
# For local development, set these environment variables or use default dev values

# Global OIDC settings - keep disabled for now (REST controller will handle OAuth flow)
quarkus.oidc.enabled=${OIDC_ENABLED:false}

# ==========================================
# Google OAuth2 Provider Configuration
# ==========================================
# Google OAuth2 uses accounts.google.com as the authorization server
# JWKS endpoint: https://www.googleapis.com/oauth2/v3/certs
quarkus.oidc.google.auth-server-url=https://accounts.google.com
quarkus.oidc.google.client-id=${GOOGLE_CLIENT_ID:your-google-client-id}
quarkus.oidc.google.credentials.secret=${GOOGLE_CLIENT_SECRET:your-google-client-secret}
quarkus.oidc.google.application-type=web-app
quarkus.oidc.google.token.issuer=https://accounts.google.com
quarkus.oidc.google.token.audience=${GOOGLE_CLIENT_ID:your-google-client-id}

# ==========================================
# Microsoft OAuth2 Provider Configuration
# ==========================================
# Microsoft OAuth2 uses login.microsoftonline.com/common for multi-tenant apps
# Supports both personal Microsoft accounts and Azure AD organizational accounts
# JWKS endpoint: https://login.microsoftonline.com/common/discovery/v2.0/keys
quarkus.oidc.microsoft.auth-server-url=https://login.microsoftonline.com/common/v2.0
quarkus.oidc.microsoft.client-id=${MICROSOFT_CLIENT_ID:your-microsoft-client-id}
quarkus.oidc.microsoft.credentials.secret=${MICROSOFT_CLIENT_SECRET:your-microsoft-client-secret}
quarkus.oidc.microsoft.application-type=web-app
quarkus.oidc.microsoft.token.issuer=https://login.microsoftonline.com/common/v2.0
quarkus.oidc.microsoft.token.audience=${MICROSOFT_CLIENT_ID:your-microsoft-client-id}

# ==========================================
# Enterprise SSO Configuration (OIDC and SAML2)
# ==========================================
# SSO configuration is stored per-organization in Organization.ssoConfig JSONB field
# These are application-wide SSO settings

# SAML2 Service Provider (SP) entity ID - identifies this application to IdPs
sso.saml2.sp-entity-id=${SSO_SAML2_SP_ENTITY_ID:https://scrumpoker.com/saml2/metadata}

# SAML2 Assertion Consumer Service (ACS) URL - where IdP posts SAML responses
sso.saml2.acs-url=${SSO_SAML2_ACS_URL:https://scrumpoker.com/api/v1/auth/sso/saml2/acs}

# SAML2 Single Logout (SLO) URL - for logout requests/responses
sso.saml2.slo-url=${SSO_SAML2_SLO_URL:https://scrumpoker.com/api/v1/auth/sso/saml2/slo}

# SSO session timeout in seconds (8 hours = 28800 seconds)
# SSO sessions are synchronized with IdP sessions
sso.session-timeout=${SSO_SESSION_TIMEOUT:28800}

# OIDC connection timeout in milliseconds (10 seconds)
sso.oidc.connect-timeout=${SSO_OIDC_TIMEOUT:10000}

# SAML2 clock skew tolerance in seconds (5 minutes = 300 seconds)
# Accounts for time differences between SP and IdP
sso.saml2.clock-skew=${SSO_SAML2_CLOCK_SKEW:300}

# ==========================================
# Stripe Configuration (Billing & Subscriptions)
# ==========================================
# Stripe API Key (secret key for server-side API calls)
# PRODUCTION NOTE: Use test mode key (sk_test_...) for dev/staging
# Set STRIPE_API_KEY environment variable with live key (sk_live_...) in production
stripe.api-key=${STRIPE_API_KEY:sk_test_51234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789}

# Stripe Webhook Secret for signature verification
# Obtain from Stripe Dashboard → Developers → Webhooks → Signing secret
stripe.webhook-secret=${STRIPE_WEBHOOK_SECRET:whsec_test_1234567890abcdefghijklmnopqrstuvwxyz}

# Stripe Price IDs for subscription tiers
# Create prices in Stripe Dashboard → Products → Create price
# Each tier maps to a Stripe Price object with recurring billing
# Note: FREE tier has no Stripe price (no charge)
stripe.price.pro=${STRIPE_PRICE_PRO:price_1234567890ProMonthly}
stripe.price.pro-plus=${STRIPE_PRICE_PRO_PLUS:price_1234567890ProPlusMonthly}
stripe.price.enterprise=${STRIPE_PRICE_ENTERPRISE:price_1234567890EnterpriseMonthly}

# ==========================================
# AWS S3 Configuration (Export File Storage)
# ==========================================
# S3 bucket for storing CSV/PDF export files
# PRODUCTION NOTE: Create bucket with lifecycle policy to delete files after 7 days
quarkus.s3.aws.region=${S3_REGION:us-east-1}
quarkus.s3.aws.credentials.type=static
quarkus.s3.aws.credentials.static-provider.access-key-id=${AWS_ACCESS_KEY_ID:AKIAIOSFODNN7EXAMPLE}
quarkus.s3.aws.credentials.static-provider.secret-access-key=${AWS_SECRET_ACCESS_KEY:wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY}

# S3 bucket name for export files
s3.bucket-name=${S3_BUCKET_NAME:scrum-poker-exports}

# Export signed URL expiration time in seconds (7 days = 604800 seconds)
export.signed-url-expiration=${EXPORT_URL_EXPIRATION:604800}

# ==========================================
# WebSocket Configuration
# ==========================================
quarkus.websocket.dispatch-to-worker=false
quarkus.websocket.max-frame-size=${WS_MAX_FRAME_SIZE:65536}

# ==========================================
# HTTP Configuration
# ==========================================
quarkus.http.port=${HTTP_PORT:8080}
quarkus.http.host=${HTTP_HOST:0.0.0.0}
quarkus.http.non-application-root-path=/q

# HTTP thread pool configuration
# PRODUCTION NOTE: Adjust based on CPU cores and expected concurrent load
# Default: 2 × CPU cores for I/O threads, 8 × CPU cores for worker threads
# For high WebSocket connection count (5,000+), increase worker threads
quarkus.thread-pool.core-threads=${QUARKUS_THREAD_POOL_CORE:8}
quarkus.thread-pool.max-threads=${QUARKUS_THREAD_POOL_MAX:200}
quarkus.thread-pool.queue-size=${QUARKUS_THREAD_POOL_QUEUE:10000}

# CORS configuration
quarkus.http.cors=true
quarkus.http.cors.origins=${CORS_ORIGINS:http://localhost:3000,http://localhost:5173}
quarkus.http.cors.methods=${CORS_METHODS:GET,POST,PUT,DELETE,OPTIONS}
quarkus.http.cors.headers=${CORS_HEADERS:accept,authorization,content-type,x-requested-with}
quarkus.http.cors.exposed-headers=${CORS_EXPOSED_HEADERS:Content-Disposition}
quarkus.http.cors.access-control-max-age=${CORS_MAX_AGE:24H}

# ==========================================
# Health Checks
# ==========================================
quarkus.health.openapi.included=true

# ==========================================
# Metrics (Prometheus)
# ==========================================
quarkus.micrometer.enabled=true
quarkus.micrometer.export.prometheus.enabled=true
quarkus.micrometer.export.prometheus.path=/q/metrics

# ==========================================
# OpenAPI Documentation
# ==========================================
quarkus.smallrye-openapi.path=/q/openapi
quarkus.swagger-ui.always-include=true
quarkus.swagger-ui.path=/q/swagger-ui

# ==========================================
# Logging Configuration
# ==========================================
# Enable JSON structured logging for production (can be overridden with LOG_JSON_FORMAT env var)
quarkus.log.console.json=${LOG_JSON_FORMAT:true}

# Default log level (overridden per environment below)
quarkus.log.level=${LOG_LEVEL:INFO}

# Console output format (used only when JSON logging is disabled)
quarkus.log.console.format=%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p [%c{3.}] (%t) %s%e%n

# JSON logging configuration
# Include MDC (Mapped Diagnostic Context) fields in JSON output (correlationId, userId, roomId, action)
quarkus.log.console.json.additional-field."correlationId".value=${mdc:correlationId}
quarkus.log.console.json.additional-field."userId".value=${mdc:userId}
quarkus.log.console.json.additional-field."roomId".value=${mdc:roomId}
quarkus.log.console.json.additional-field."action".value=${mdc:action}

# Exclude verbose Quarkus internal logs from INFO level
quarkus.log.category."io.quarkus".level=WARN
quarkus.log.category."io.vertx".level=WARN
quarkus.log.category."io.netty".level=WARN

# Production log level: WARN (errors and warnings only)
%prod.quarkus.log.level=WARN
%prod.quarkus.log.console.json=true

# Staging log level: INFO (includes API requests and service calls)
%staging.quarkus.log.level=INFO
%staging.quarkus.log.console.json=true

# Log Aggregation Configuration
# ==========================================
# This application outputs structured JSON logs to stdout/stderr for aggregation by external systems.
#
# Supported Log Aggregation Options:
#
# Option 1: Grafana Loki (Recommended for Kubernetes)
# - Deploy Promtail as DaemonSet to tail container logs
# - Promtail ships logs to Loki for storage and querying
# - Grafana provides visualization and alerting
# - Configuration: Promtail scrapes /var/log/containers/*.log with JSON parser
#
# Option 2: AWS CloudWatch Logs (Managed AWS deployment)
# - Configure CloudWatch agent or Fluent Bit to capture container stdout/stderr
# - Logs are automatically shipped to CloudWatch Logs group
# - CloudWatch Insights provides log querying
# - Configuration: Set LOG_GROUP_NAME and LOG_STREAM_NAME environment variables
#
# Option 3: GCP Cloud Logging (Managed GCP deployment)
# - GKE automatically captures container logs and ships to Cloud Logging
# - No additional agent configuration required
# - Cloud Logging Console provides querying and filtering
#
# JSON Log Schema:
# - timestamp: ISO8601 format (automatically added by Quarkus)
# - level: DEBUG, INFO, WARN, ERROR
# - logger: Java class name (e.g., com.scrumpoker.api.RoomController)
# - message: Human-readable log message
# - correlationId: Unique request/WebSocket session identifier (from MDC)
# - userId: Authenticated user ID (from MDC, omitted for anonymous)
# - roomId: Estimation room context (from MDC, when applicable)
# - action: Semantic business action (from MDC, e.g., "vote.cast", "room.created")
# - duration: Operation latency in milliseconds (for timed operations)
# - stackTrace: Exception stack trace (for ERROR level)
#
# Query Optimization:
# - Index the following fields in your log aggregation system: correlationId, userId, roomId, action, level
# - These fields enable efficient filtering and correlation of related log entries
#
# Log Retention Policy:
# - Application logs: 30 days (general operational logs)
# - Audit logs: 90 days (compliance and security events from AuditLogService)
#
# Example Loki Query:
# {app="planning-poker"} | json | correlationId="abc-123-def" | level="ERROR"
#
# Example CloudWatch Insights Query:
# fields @timestamp, message, correlationId, userId, roomId, action
# | filter correlationId = "abc-123-def"
# | sort @timestamp desc

# ==========================================
# Development Mode Configuration
# ==========================================
%dev.quarkus.log.level=DEBUG
%dev.quarkus.hibernate-orm.log.sql=true
%dev.quarkus.http.cors=true
%dev.quarkus.http.cors.origins=/.*/
# Temporarily disable Redis health check for dev mode (until Redis is set up)
%dev.quarkus.redis.health.enabled=false

# ==========================================
# Test Configuration
# ==========================================
# Test configuration moved to src/test/resources/application.properties
# Dev Services (Testcontainers) will automatically start PostgreSQL and Redis
# when no explicit datasource URLs are configured in the test profile

# ==========================================
# Production JVM Tuning Configuration
# ==========================================
# IMPORTANT: These settings are passed via JAVA_OPTS environment variable in production
# They are documented here for reference and deployment configuration
#
# Recommended JVM settings for production workload (5,000 WebSocket connections):
#
# Heap Size (1GB minimum for 5,000 connections):
#   -Xms1g -Xmx1g
#   Estimate: ~200KB per WebSocket connection = 1GB for connection state
#
# Garbage Collection (G1GC recommended for large heap):
#   -XX:+UseG1GC
#   -XX:MaxGCPauseMillis=200
#   -XX:+UseStringDeduplication
#
# GC Logging (for troubleshooting):
#   -Xlog:gc*:file=/tmp/gc.log:time,uptime,level,tags:filecount=5,filesize=10M
#
# Memory Management:
#   -XX:MaxMetaspaceSize=256m
#   -XX:+HeapDumpOnOutOfMemoryError
#   -XX:HeapDumpPath=/tmp/heapdump.hprof
#
# Example Kubernetes Deployment JAVA_OPTS:
#   env:
#     - name: JAVA_OPTS
#       value: >-
#         -Xms1g -Xmx1g
#         -XX:+UseG1GC
#         -XX:MaxGCPauseMillis=200
#         -XX:MaxMetaspaceSize=256m
#         -XX:+HeapDumpOnOutOfMemoryError
#         -XX:HeapDumpPath=/tmp/heapdump.hprof
#         -Xlog:gc*:file=/tmp/gc.log:time:filecount=5,filesize=10M
#
# Container Memory Limit:
#   Set Kubernetes memory limit to 1.5GB (1GB heap + 0.5GB non-heap)
#   resources:
#     limits:
#       memory: 1536Mi
#     requests:
#       memory: 1536Mi
#
# Performance Monitoring:
#   - Monitor heap usage via JVM metrics (jvm_memory_used_bytes) in Prometheus
#   - Watch for GC pauses >200ms in GC logs
#   - Check for memory leaks (heap growth without plateau)
#   - Use VisualVM or JDK Flight Recorder for profiling if needed
#
# Scaling Guidance:
#   - For >10,000 WebSocket connections: increase heap to 2GB
#   - For CPU-bound workload: increase worker threads (QUARKUS_THREAD_POOL_MAX)
#   - For DB bottleneck: increase connection pool (DB_POOL_MAX_SIZE)
#   - For Redis bottleneck: increase Redis pool (REDIS_POOL_MAX_SIZE)
# ==========================================
